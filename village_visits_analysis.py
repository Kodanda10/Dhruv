#!/usr/bin/env python3
"""
Detailed Village-Level Analysis for OP Choudhary visits
Extracts and analyzes specific villages mentioned in tweets
"""

import re
import json
from collections import Counter, defaultdict
from datetime import datetime

def decode_unicode_escapes(text):
    """Convert RTF Unicode escapes to actual characters"""
    def replace_unicode(match):
        code = int(match.group(1))
        try:
            return chr(code)
        except ValueError:
            return match.group(0)  # Keep original if invalid

    # Handle \uXXXX patterns with spaces (RTF format)
    text = re.sub(r'\\u(\d{4,5})\s*', replace_unicode, text)

    # Handle consecutive Unicode escapes
    text = re.sub(r'\\u(\d{4,5})\\u(\d{4,5})', lambda m: chr(int(m.group(1))) + chr(int(m.group(2))), text)

    # Clean up RTF control codes
    text = re.sub(r'\\[a-z]+\d*', '', text)
    text = re.sub(r'\\uc\d+', '', text)

    return text

def parse_rtf_tweets(rtf_content):
    """Parse tweets from RTF content"""
    tweets = []

    # Split by tweet sections
    tweet_sections = re.split(r'Tweet #\d+', rtf_content)[1:]  # Skip header

    for i, section in enumerate(tweet_sections, 1):
        tweet = {}

        # Extract ID
        id_match = re.search(r'ID: (\d+)', section)
        tweet['id'] = id_match.group(1) if id_match else f'unknown_{i}'

        # Extract date
        date_match = re.search(r'Date: ([^\n]+)', section)
        tweet['date'] = date_match.group(1).strip() if date_match else 'unknown'

        # Extract author
        author_match = re.search(r'Author: (@[^\n]+)', section)
        tweet['author'] = author_match.group(1).strip() if author_match else 'unknown'

        # Extract status
        status_match = re.search(r'Status: ([^\n]+)', section)
        tweet['status'] = status_match.group(1).strip() if status_match else 'unknown'

        # Extract text (between "Text:" and "Metrics:")
        text_match = re.search(r'Text:([\s\S]*?)(?=Metrics:)', section)
        if text_match:
            text = text_match.group(1).strip()
            # Remove RTF braces and control codes first
            text = re.sub(r'[{}]', '', text)
            text = decode_unicode_escapes(text)
            # Clean up extra whitespace and line breaks
            text = re.sub(r'\s+', ' ', text)
            text = text.strip()
            tweet['text'] = text
        else:
            tweet['text'] = ''

        # Extract metrics
        likes_match = re.search(r'Likes: (\d+)', section)
        tweet['likes'] = int(likes_match.group(1)) if likes_match else 0

        replies_match = re.search(r'Replies: (\d+)', section)
        tweet['replies'] = int(replies_match.group(1)) if replies_match else 0

        retweets_match = re.search(r'Retweets: (\d+)', section)
        tweet['retweets'] = int(retweets_match.group(1)) if retweets_match else 0

        quotes_match = re.search(r'Quotes: (\d+)', section)
        tweet['quotes'] = int(quotes_match.group(1)) if quotes_match else 0

        tweet['engagement'] = tweet['likes'] + tweet['replies'] + tweet['retweets'] + tweet['quotes']

        tweets.append(tweet)

    return tweets

def extract_villages_detailed(text):
    """Extract village names with more sophisticated pattern matching"""
    villages = []

    # Look for specific village names that are commonly mentioned in Chhattisgarh
    known_villages = [
        '‡§§‡•Å‡§∞‡§Ç‡§ó‡§æ', '‡§™‡§Ç‡§ö‡§ß‡§æ‡§∞', '‡§ï‡•Å‡§ï‡•Å‡§∞‡•ç‡§¶‡§æ', '‡§¨‡§æ‡§∏‡§®‡§™‡§æ‡§≤‡•Ä', '‡§™‡•Å‡§∏‡•å‡§∞', '‡§ï‡§≤‡§Æ‡•Ä',
        '‡§ñ‡§∞‡§∏‡§ø‡§Ø‡§æ', '‡§ß‡§∞‡§Æ‡§ú‡§Ø‡§ó‡§¢‡§º', '‡§ó‡•å‡§∞‡•á‡§≤‡§æ', '‡§Æ‡§®‡•á‡§Ç‡§¶‡•ç‡§∞‡§ó‡§¢‡§º', '‡§Ö‡§Ç‡§§‡§æ‡§ó‡§¢‡§º',
        '‡§™‡§Ç‡§°‡§∞‡§ø‡§Ø‡§æ', '‡§≤‡•à‡§≤‡•Ç‡§Ç‡§ó‡§æ', '‡§¨‡§∞‡§Æ‡§ï‡§≤‡§æ', '‡§ï‡•ã‡§∞‡§¨‡§æ', '‡§ï‡§ü‡§ò‡•ã‡§∞‡§æ', '‡§™‡§æ‡§≤‡•Ä',
        '‡§Æ‡§∏‡•ç‡§§‡•Ç‡§∞‡•Ä', '‡§§‡§ñ‡§§‡§™‡•Å‡§∞', '‡§∞‡§§‡§®‡§™‡•Å‡§∞', '‡§ï‡•ã‡§§‡§Æ‡§æ', '‡§¨‡•á‡§≤‡§§‡§∞‡§æ', '‡§µ‡•à‡§∂‡§æ‡§≤‡•Ä ‡§®‡§ó‡§∞',
        '‡§Ö‡§≠‡§®‡§™‡•Å‡§∞', '‡§Ö‡§∞‡§Ç‡§ó', '‡§ß‡§∞‡§∏‡•Ä‡§µ‡§æ‡§Å', '‡§ó‡§à‡§¨‡§Ç‡§¶', '‡§≠‡§ø‡§≤‡§æ‡§à', '‡§™‡§æ‡§ü‡§®', '‡§ß‡§Æ‡§ß‡§æ',
        '‡§®‡§µ‡§æ‡§ó‡§¢‡§º', '‡§ó‡•Å‡§Ç‡§°‡§∞‡§¶‡•á‡§π‡•Ä', '‡§õ‡•Å‡§∞‡•Ä‡§Ø‡§æ', '‡§Ö‡§Ç‡§¨‡§æ‡§ó‡§¢‡§º ‡§ö‡•å‡§ï‡•Ä', '‡§Æ‡•ã‡§π‡§≤‡§æ-‡§Æ‡§æ‡§®‡§™‡•Å‡§∞',
        '‡§ï‡•ã‡§∞‡§ø‡§Ø‡§æ', '‡§¨‡§æ‡§à‡§ñ‡§∞', '‡§ú‡§æ‡§Ç‡§ú‡§ó‡•Ä‡§∞', '‡§Ö‡§ï‡§≤‡§§‡§∞‡§æ', '‡§™‡§æ‡§Æ‡§ó‡§¢‡§º', '‡§¨‡§≤‡•å‡§¶‡§æ',
        '‡§∏‡§ï‡§§‡•Ä', '‡§¶‡§æ‡§≠‡§∞‡§æ', '‡§ï‡§µ‡§∞‡•ç‡§ß‡§æ', '‡§¨‡•ã‡§°‡§º‡§≤‡§æ', '‡§ï‡•Å‡§Ç‡§°‡•Ä', '‡§Æ‡§π‡§æ‡§∏‡§Æ‡•Å‡§Ç‡§¶',
        '‡§¨‡§æ‡§ó‡§¨‡§æ‡§π‡§∞‡§æ', '‡§∏‡§∞‡•ç‡§ú‡§æ', '‡§™‡§ø‡§•‡•å‡§∞‡§æ', '‡§ï‡•Å‡§∞‡•Ç‡§¶', '‡§Æ‡§ó‡§∞‡§≤‡•ã‡§°', '‡§≠‡•ã‡§•‡§≤‡•Ä',
        '‡§ì‡§∞‡§õ‡§æ', '‡§ï‡•ã‡§Ø‡§≤‡•Ä‡§¨‡•á‡§°‡§º‡§æ', '‡§≠‡§æ‡§®‡•Å‡§™‡•ç‡§∞‡§§‡§æ‡§™‡§™‡•Å‡§∞', '‡§Ö‡§Ç‡§§‡§æ‡§ó‡§¢‡§º', '‡§≠‡§æ‡§®‡•Å‡§™‡•ç‡§∞‡§§‡§æ‡§™‡§™‡•Å‡§∞',
        '‡§ï‡•ã‡§Ø‡§≤‡•Ä‡§¨‡•á‡§°‡§º‡§æ', '‡§Ö‡§Ç‡§§‡§æ‡§ó‡§¢‡§º', '‡§≠‡§æ‡§®‡•Å‡§™‡•ç‡§∞‡§§‡§æ‡§™‡§™‡•Å‡§∞', '‡§ï‡•ã‡§Ø‡§≤‡•Ä‡§¨‡•á‡§°‡§º‡§æ'
    ]

    # Check for known villages first
    for village in known_villages:
        if village in text:
            villages.append({
                'name': village,
                'indicator': 'known_village',
                'confidence': 'high'
            })

    # Look for patterns with village indicators
    village_patterns = [
        r'‡§ó‡•ç‡§∞‡§æ‡§Æ\s+([‡§Ö-‡§π\s]{2,25})(?:\s|$|[,‡•§])',  # ‡§ó‡•ç‡§∞‡§æ‡§Æ followed by Hindi name
        r'‡§ó‡§æ‡§Å‡§µ\s+([‡§Ö-‡§π\s]{2,25})(?:\s|$|[,‡•§])',   # ‡§ó‡§æ‡§Å‡§µ followed by Hindi name
        r'‡§¨‡§∏‡•ç‡§§‡•Ä\s+([‡§Ö-‡§π\s]{2,25})(?:\s|$|[,‡•§])',  # ‡§¨‡§∏‡•ç‡§§‡•Ä followed by Hindi name
        r'([‡§Ö-‡§π\s]{3,20})\s*‡§ó‡•ç‡§∞‡§æ‡§Æ',  # Name before ‡§ó‡•ç‡§∞‡§æ‡§Æ
        r'([‡§Ö-‡§π\s]{3,20})\s*‡§ó‡§æ‡§Å‡§µ',   # Name before ‡§ó‡§æ‡§Å‡§µ
        r'([‡§Ö-‡§π\s]{3,20})\s*‡§¨‡§∏‡•ç‡§§‡•Ä',  # Name before ‡§¨‡§∏‡•ç‡§§‡•Ä
    ]

    for pattern in village_patterns:
        matches = re.findall(pattern, text)
        for match in matches:
            village_name = match.strip()
            # Clean up the name - remove non-Hindi characters except spaces
            village_name = re.sub(r'[^\u0900-\u097F\s]', '', village_name)
            village_name = re.sub(r'\s+', ' ', village_name).strip()

            # Skip if too short or too long
            if len(village_name) < 2 or len(village_name) > 25:
                continue

            # Skip common words that might be false positives
            skip_words = ['‡§ï‡•á', '‡§ï‡•Ä', '‡§ï‡§æ', '‡§ï‡•ã', '‡§∏‡•á', '‡§Æ‡•á‡§Ç', '‡§™‡§∞', '‡§®‡•á', '‡§π‡•à', '‡§•‡§æ', '‡§•‡•Ä', '‡§π‡•ã', '‡§ï‡§∞', '‡§ï‡§∞‡§ï‡•á']
            if village_name.lower() in skip_words:
                continue

            # Determine indicator
            indicator = 'unknown'
            if '‡§ó‡•ç‡§∞‡§æ‡§Æ' in text[max(0, text.find(village_name)-5):text.find(village_name)+len(village_name)+5]:
                indicator = '‡§ó‡•ç‡§∞‡§æ‡§Æ'
            elif '‡§ó‡§æ‡§Å‡§µ' in text[max(0, text.find(village_name)-5):text.find(village_name)+len(village_name)+5]:
                indicator = '‡§ó‡§æ‡§Å‡§µ'
            elif '‡§¨‡§∏‡•ç‡§§‡•Ä' in text[max(0, text.find(village_name)-5):text.find(village_name)+len(village_name)+5]:
                indicator = '‡§¨‡§∏‡•ç‡§§‡•Ä'

            villages.append({
                'name': village_name,
                'indicator': indicator,
                'confidence': 'medium'
            })

    # Remove duplicates while preserving order and preferring higher confidence
    seen = {}
    for village in villages:
        key = village['name'].lower()
        if key not in seen or (seen[key]['confidence'] == 'medium' and village['confidence'] == 'high'):
            seen[key] = village

    return list(seen.values())

def analyze_village_visits(tweets):
    """Analyze village visits from tweets"""
    village_visits = []
    village_counter = Counter()
    village_details = defaultdict(lambda: {
        'visits': 0,
        'tweets': [],
        'total_engagement': 0,
        'dates': [],
        'indicators': set()
    })

    for tweet in tweets:
        if not tweet['text']:
            continue

        villages = extract_villages_detailed(tweet['text'])

        if villages:
            for village in villages:
                village_name = village['name']
                village_counter[village_name] += 1

                # Store detailed information
                village_details[village_name]['visits'] += 1
                village_details[village_name]['total_engagement'] += tweet['engagement']
                village_details[village_name]['dates'].append(tweet['date'])
                village_details[village_name]['indicators'].add(village['indicator'])

                # Store tweet preview
                preview = tweet['text'][:150] + '...' if len(tweet['text']) > 150 else tweet['text']
                village_details[village_name]['tweets'].append({
                    'id': tweet['id'],
                    'date': tweet['date'],
                    'text': preview,
                    'engagement': tweet['engagement']
                })

                village_visits.append({
                    'village': village_name,
                    'indicator': village['indicator'],
                    'confidence': village['confidence'],
                    'tweet_id': tweet['id'],
                    'date': tweet['date'],
                    'engagement': tweet['engagement'],
                    'text_preview': preview
                })

    return village_visits, village_counter, village_details

def create_village_mindmap(village_details):
    """Create mindmap structure for villages"""
    mindmap = {
        'name': '‡§∞‡§æ‡§Ø‡§ó‡§¢‡§º ‡§ú‡§ø‡§≤‡§æ ‡§ó‡•ç‡§∞‡§æ‡§Æ',
        'type': 'district',
        'children': []
    }

    # Sort villages by visit frequency
    sorted_villages = sorted(village_details.items(), key=lambda x: x[1]['visits'], reverse=True)

    for village_name, details in sorted_villages:
        village_node = {
            'name': village_name,
            'type': 'village',
            'visits': details['visits'],
            'total_engagement': details['total_engagement'],
            'indicators': list(details['indicators']),
            'children': []
        }

        # Add visit events as children
        for tweet in details['tweets'][:3]:  # Top 3 tweets per village
            event_node = {
                'name': f"‡§µ‡§ø‡§ú‡§º‡§ø‡§ü {tweet['date'][:10]}",
                'type': 'visit',
                'engagement': tweet['engagement'],
                'tweet_id': tweet['id'],
                'children': []
            }
            village_node['children'].append(event_node)

        mindmap['children'].append(village_node)

    return mindmap

def main():
    # Read RTF file
    with open('fetched_tweets_readable.rtf', 'r', encoding='utf-8', errors='ignore') as f:
        rtf_content = f.read()

    # Parse tweets
    tweets = parse_rtf_tweets(rtf_content)
    print(f"‚úÖ Parsed {len(tweets)} tweets successfully")

    # Analyze village visits
    village_visits, village_counter, village_details = analyze_village_visits(tweets)

    # Create mindmap
    mindmap_data = create_village_mindmap(village_details)

    print("\n" + "="*80)
    print("üèòÔ∏è ‡§ó‡•ç‡§∞‡§æ‡§Æ/‡§ó‡§æ‡§Å‡§µ ‡§µ‡§ø‡§ú‡§º‡§ø‡§ü ‡§µ‡§ø‡§∂‡•ç‡§≤‡•á‡§∑‡§£ - OP CHOUDHARY")
    print("VILLAGE VISITS ANALYSIS - MINDMAP VIEW")
    print("="*80)

    print(f"\nüìä ‡§ó‡•ç‡§∞‡§æ‡§Æ ‡§ï‡§µ‡§∞‡•á‡§ú ‡§Ü‡§Å‡§ï‡§°‡§º‡•á (Village Coverage Statistics)")
    total_tweets = len(tweets)
    tweets_with_villages = len(set(visit['tweet_id'] for visit in village_visits))
    unique_villages = len(village_counter)

    print(f"‡§ï‡•Å‡§≤ ‡§ü‡•ç‡§µ‡•Ä‡§ü‡•ç‡§∏: {total_tweets:,}")
    print(f"‡§ó‡•ç‡§∞‡§æ‡§Æ ‡§â‡§≤‡•ç‡§≤‡•á‡§ñ ‡§ü‡•ç‡§µ‡•Ä‡§ü‡•ç‡§∏: {tweets_with_villages:,}")
    print(f"‡§ó‡•ç‡§∞‡§æ‡§Æ ‡§ï‡§µ‡§∞‡•á‡§ú ‡§™‡•ç‡§∞‡§§‡§ø‡§∂‡§§: {(tweets_with_villages/total_tweets*100):.1f}%")
    print(f"‡§Ö‡§¶‡•ç‡§µ‡§ø‡§§‡•Ä‡§Ø ‡§ó‡•ç‡§∞‡§æ‡§Æ: {unique_villages:,}")

    print(f"\nüèòÔ∏è ‡§∂‡•Ä‡§∞‡•ç‡§∑ 20 ‡§ó‡•ç‡§∞‡§æ‡§Æ ‡§µ‡§ø‡§ú‡§º‡§ø‡§ü (Top 20 Village Visits)")
    print("-" * 60)
    print(f"{'‡§ó‡•ç‡§∞‡§æ‡§Æ ‡§®‡§æ‡§Æ':<25} {'‡§µ‡§ø‡§ú‡§º‡§ø‡§ü':<8} {'‡§è‡§Ç‡§ó‡•á‡§ú‡§Æ‡•á‡§Ç‡§ü':<12} {'‡§á‡§Ç‡§°‡§ø‡§ï‡•á‡§ü‡§∞'}")
    print("-" * 60)

    for village, count in village_counter.most_common(20):
        details = village_details[village]
        total_engagement = details['total_engagement']
        indicators = ', '.join(list(details['indicators'])[:2])  # Show top 2 indicators
        print(f"{village:<25} {count:<8} {total_engagement:<12} {indicators}")

    print(f"\nüå≥ ‡§Æ‡§æ‡§á‡§Ç‡§°‡§Æ‡•à‡§™ ‡§∏‡§Ç‡§∞‡§ö‡§®‡§æ (Mindmap Structure)")
    print(f"‡§∞‡§æ‡§Ø‡§ó‡§¢‡§º ‡§ú‡§ø‡§≤‡§æ ‡§ó‡•ç‡§∞‡§æ‡§Æ ({len(mindmap_data['children'])} ‡§ó‡•ç‡§∞‡§æ‡§Æ)")
    for i, village in enumerate(mindmap_data['children'][:10], 1):  # Show top 10
        print(f"  ‚îú‚îÄ‚îÄ {village['name']} ({village['visits']} ‡§µ‡§ø‡§ú‡§º‡§ø‡§ü)")
        for j, visit in enumerate(village['children'][:2], 1):  # Show 2 visits per village
            print(f"      ‚îú‚îÄ‚îÄ {visit['name']} (‡§è‡§Ç‡§ó‡•á‡§ú‡§Æ‡•á‡§Ç‡§ü: {visit['engagement']})")

    print(f"\nüìÖ ‡§ó‡•ç‡§∞‡§æ‡§Æ‡§µ‡§æ‡§∞ ‡§µ‡§ø‡§ú‡§º‡§ø‡§ü ‡§ü‡§æ‡§á‡§Æ‡§≤‡§æ‡§á‡§® (Village Visit Timeline)")
    # Group by month
    monthly_visits = defaultdict(lambda: defaultdict(int))
    for visit in village_visits:
        try:
            date = datetime.strptime(visit['date'], '%Y-%m-%d %H:%M:%S')
            month_key = f"{date.year}-{date.month:02d}"
            monthly_visits[month_key][visit['village']] += 1
        except:
            pass

    if monthly_visits:
        print("‡§Æ‡§æ‡§∏‡§ø‡§ï ‡§ó‡•ç‡§∞‡§æ‡§Æ ‡§µ‡§ø‡§ú‡§º‡§ø‡§ü ‡§∏‡§æ‡§∞‡§æ‡§Ç‡§∂:")
        for month in sorted(monthly_visits.keys(), reverse=True)[:6]:  # Last 6 months
            villages_in_month = monthly_visits[month]
            total_visits = sum(villages_in_month.values())
            top_village = max(villages_in_month.items(), key=lambda x: x[1])
            print(f"  {month}: {total_visits} ‡§µ‡§ø‡§ú‡§º‡§ø‡§ü, ‡§∂‡•Ä‡§∞‡•ç‡§∑ ‡§ó‡•ç‡§∞‡§æ‡§Æ: {top_village[0]} ({top_village[1]}x)")

    print(f"\nüéØ ‡§ó‡•ç‡§∞‡§æ‡§Æ ‡§µ‡§ø‡§ú‡§º‡§ø‡§ü ‡§Ö‡§Ç‡§§‡§∞‡•ç‡§¶‡•É‡§∑‡•ç‡§ü‡§ø (Village Visit Insights)")
    if village_counter:
        most_visited = village_counter.most_common(1)[0]
        print(f"‡§∏‡§¨‡§∏‡•á ‡§Ö‡§ß‡§ø‡§ï ‡§µ‡§ø‡§ú‡§º‡§ø‡§ü ‡§ó‡•ç‡§∞‡§æ‡§Æ: {most_visited[0]} ({most_visited[1]} ‡§¨‡§æ‡§∞)")

        avg_visits_per_village = sum(village_counter.values()) / len(village_counter)
        print(f"‡§™‡•ç‡§∞‡§§‡§ø ‡§ó‡•ç‡§∞‡§æ‡§Æ ‡§î‡§∏‡§§ ‡§µ‡§ø‡§ú‡§º‡§ø‡§ü: {avg_visits_per_village:.1f}")

        # Engagement analysis
        high_engagement_villages = [(v, d['total_engagement']) for v, d in village_details.items()]
        high_engagement_villages.sort(key=lambda x: x[1], reverse=True)

        if high_engagement_villages:
            top_engagement = high_engagement_villages[0]
            print(f"‡§∏‡§∞‡•ç‡§µ‡§æ‡§ß‡§ø‡§ï ‡§è‡§Ç‡§ó‡•á‡§ú‡§Æ‡•á‡§Ç‡§ü ‡§ó‡•ç‡§∞‡§æ‡§Æ: {top_engagement[0]} ({top_engagement[1]} ‡§è‡§Ç‡§ó‡•á‡§ú‡§Æ‡•á‡§Ç‡§ü)")

    print(f"\nüìã ‡§ó‡•ç‡§∞‡§æ‡§Æ ‡§™‡•ç‡§∞‡§ï‡§æ‡§∞ ‡§µ‡§ø‡§§‡§∞‡§£ (Village Type Distribution)")
    indicator_counts = Counter()
    for visit in village_visits:
        indicator_counts[visit['indicator']] += 1

    for indicator, count in indicator_counts.most_common():
        pct = (count / len(village_visits)) * 100
        print(f"{indicator}: {count} ({pct:.1f}%)")

    print(f"\nüèòÔ∏è ‡§µ‡§ø‡§∏‡•ç‡§§‡•É‡§§ ‡§ó‡•ç‡§∞‡§æ‡§Æ ‡§∏‡•Ç‡§ö‡•Ä (Detailed Village List)")
    print("-" * 80)
    for village, count in village_counter.most_common(15):
        details = village_details[village]
        recent_visit = max(details['dates']) if details['dates'] else 'unknown'
        total_engagement = details['total_engagement']
        indicators = list(details['indicators'])

        print(f"üèòÔ∏è {village}")
        print(f"   ‡§µ‡§ø‡§ú‡§º‡§ø‡§ü: {count} | ‡§è‡§Ç‡§ó‡•á‡§ú‡§Æ‡•á‡§Ç‡§ü: {total_engagement} | ‡§Ö‡§Ç‡§§‡§ø‡§Æ ‡§µ‡§ø‡§ú‡§º‡§ø‡§ü: {recent_visit[:10]}")
        print(f"   ‡§á‡§Ç‡§°‡§ø‡§ï‡•á‡§ü‡§∞: {', '.join(indicators)}")
        try:
            # Handle Unicode encoding issues
            tweet_text = details['tweets'][0]['text'][:100]
            # Replace problematic characters
            tweet_text = tweet_text.encode('utf-8', errors='replace').decode('utf-8')
            print(f"   ‡§π‡§æ‡§≤‡§ø‡§Ø‡§æ ‡§ü‡•ç‡§µ‡•Ä‡§ü: {tweet_text}...")
        except (UnicodeEncodeError, UnicodeDecodeError):
            print(f"   ‡§π‡§æ‡§≤‡§ø‡§Ø‡§æ ‡§ü‡•ç‡§µ‡•Ä‡§ü: [Unicode text - {len(details['tweets'][0]['text'])} chars]...")
        print()

    # Save detailed data
    output_data = {
        'village_visits': village_visits,
        'village_counter': dict(village_counter),
        'village_details': dict(village_details),
        'mindmap': mindmap_data,
        'summary_stats': {
            'total_tweets': len(tweets),
            'tweets_with_villages': tweets_with_villages,
            'unique_villages': unique_villages,
            'total_visits': len(village_visits)
        }
    }

    try:
        with open('village_visits_analysis.json', 'w', encoding='utf-8') as f:
            json.dump(output_data, f, ensure_ascii=False, indent=2, default=str)
    except UnicodeEncodeError:
        with open('village_visits_analysis.json', 'w', encoding='utf-8') as f:
            json.dump(output_data, f, ensure_ascii=True, indent=2, default=str)

    print(f"\nüíæ ‡§µ‡§ø‡§∏‡•ç‡§§‡•É‡§§ ‡§ó‡•ç‡§∞‡§æ‡§Æ ‡§°‡•á‡§ü‡§æ 'village_visits_analysis.json' ‡§Æ‡•á‡§Ç ‡§∏‡§π‡•á‡§ú‡§æ ‡§ó‡§Ø‡§æ")
    print("="*80)
    print("‚úÖ ‡§ó‡•ç‡§∞‡§æ‡§Æ ‡§µ‡§ø‡§ú‡§º‡§ø‡§ü ‡§µ‡§ø‡§∂‡•ç‡§≤‡•á‡§∑‡§£ ‡§™‡•Ç‡§∞‡§æ - ‡§Æ‡§æ‡§á‡§Ç‡§°‡§Æ‡•à‡§™ ‡§ï‡•á ‡§≤‡§ø‡§è ‡§§‡•à‡§Ø‡§æ‡§∞")
    print("="*80)

if __name__ == "__main__":
    main()