# ЁЯза Parsing Methodology & LangExtract Integration

**Date:** October 17, 2025  
**Project:** OP Choudhary Social Media Analytics Dashboard

---

## ЁЯУЪ **TABLE OF CONTENTS**

1. [Current Parsing Methodology](#current-parsing-methodology)
2. [How Our Parser Works](#how-our-parser-works)
3. [LangExtract Integration Possibilities](#langextract-integration-possibilities)
4. [Human-in-the-Loop Learning System](#human-in-the-loop-learning-system)
5. [Implementation Roadmap](#implementation-roadmap)

---

## 1. CURRENT PARSING METHODOLOGY

### **Overview:**
Our parsing system is a **hybrid approach** that combines:
- **Regex-based pattern matching** (for Hindi entities)
- **AI-powered semantic understanding** (for context and classification)
- **Human validation** (for training data quality)

### **Input:**
```
"рдЕрдВрддрд╛рдЧрдврд╝ рд╡рд┐рдзрд╛рдирд╕рднрд╛ рдХреЗ рд▓реЛрдХрдкреНрд░рд┐рдп рд╡рд┐рдзрд╛рдпрдХ рдПрд╡рдВ рдЫрддреНрддреАрд╕рдЧрдврд╝ рднрд╛рдЬрдкрд╛ рдХреЗ рдкреВрд░реНрд╡ рдЕрдзреНрдпрдХреНрд╖ 
рдорд╛рдирдиреАрдп рд╢реНрд░реА рд╡рд┐рдХреНрд░рдо рдЙрд╕реЗрдВрдбреА рдЬреА рдХреЛ рдЬрдиреНрдорджрд┐рди рдХреА рд╣рд╛рд░реНрджрд┐рдХ рдмрдзрд╛рдИ рдПрд╡рдВ рд╢реБрднрдХрд╛рдордирд╛рдпреЗрдВред"
```

### **Output:**
```json
{
  "event_type": "birthday_wishes",
  "event_type_confidence": 0.95,
  "locations": [
    {"name": "рдЕрдВрддрд╛рдЧрдврд╝", "type": "constituency"},
    {"name": "рдЫрддреНрддреАрд╕рдЧрдврд╝", "type": "state"}
  ],
  "people_mentioned": ["рд╡рд┐рдХреНрд░рдо рдЙрд╕реЗрдВрдбреА"],
  "organizations": ["рднрд╛рдЬрдкрд╛"],
  "schemes_mentioned": [],
  "overall_confidence": 0.78
}
```

---

## 2. HOW OUR PARSER WORKS

### **Step-by-Step Process:**

#### **STEP 1: Text Preprocessing**
```python
# File: api/src/parsing/enhanced_parser.py

def preprocess(text: str) -> str:
    """
    Clean and normalize Hindi text
    """
    # Remove extra whitespace
    text = re.sub(r'\s+', ' ', text).strip()
    
    # Normalize Unicode (handle different Hindi encodings)
    text = unicodedata.normalize('NFC', text)
    
    # Remove URLs, mentions, hashtags (if needed)
    # text = re.sub(r'https?://\S+', '', text)
    
    return text
```

**What happens:**
- Removes extra spaces
- Normalizes Unicode characters (important for Hindi!)
- Optionally removes URLs, @mentions

---

#### **STEP 2: Entity Extraction (Regex-based)**

Our enhanced parser uses **comprehensive regex patterns** for Hindi entities:

```python
# Define patterns for common places
PLACE_KEYWORDS = re.compile(
    r'(рдирдИ рджрд┐рд▓реНрд▓реА|рдирдпреА рджрд┐рд▓реНрд▓реА|рд░рд╛рдпрдЧрдврд╝|рджрд┐рд▓реНрд▓реА|рд░рд╛рдпрдкреБрд░|рднрд╛рд░рдд|рдЫрддреНрддреАрд╕рдЧрдврд╝|'
    r'рдЦрд░рд╕рд┐рдпрд╛|рдЧрдврд╝ рдЙрдорд░рд┐рдпрд╛|рдмрд╕реНрддрд░|рд╕рд░рдЧреБрдЬрд╛|рдЬрд╢рдкреБрд░|рдмрдЧреАрдЪрд╛|рдЕрдВрддрд╛рдЧрдврд╝)',
    re.IGNORECASE
)

# Pattern for "X рдореЗрдВ" (in X) - context-based location detection
LOCATION_CONTEXT_PATTERN = re.compile(
    r'([\u0900-\u097F\u0600-\u06FF\u0020-\u007E\s]{2,}?)\s+рдореЗрдВ',
    re.UNICODE
)

def _extract_locations(self, text: str) -> List[Dict[str, str]]:
    """
    Extract locations using multiple strategies
    """
    locations = set()
    
    # Strategy 1: Direct keyword matching
    for match in PLACE_KEYWORDS.finditer(text):
        locations.add(match.group(0))
    
    # Strategy 2: Context-based ("X рдореЗрдВ" pattern)
    for match in LOCATION_CONTEXT_PATTERN.finditer(text):
        potential_loc = match.group(1).strip()
        # Verify it's a known location
        if PLACE_KEYWORDS.search(potential_loc):
            locations.add(potential_loc)
    
    # Convert to structured format
    return [
        {"name": loc, "type": self._classify_location_type(loc)} 
        for loc in locations
    ]
```

**What happens:**
1. **Direct Matching**: Looks for known place names (рд░рд╛рдпрдЧрдврд╝, рджрд┐рд▓реНрд▓реА, etc.)
2. **Context Matching**: Finds patterns like "рдЕрдВрддрд╛рдЧрдврд╝ рдореЗрдВ" (in Antagarh)
3. **Validation**: Cross-checks against known place database

---

#### **STEP 3: People Extraction**

```python
PEOPLE_KEYWORDS = re.compile(
    r'(рд╡рд┐рдХреНрд░рдо рдЙрд╕реЗрдВрдбреА|рд░рдорди рд╕рд┐рдВрд╣|рднреВрдкреЗрд╢ рдмрдШреЗрд▓|рдЕрдЬреАрдд рдЬреЛрдЧреА|рджрд┐рд▓реАрдк рд╕рд┐рдВрд╣ рдЬреВрджреЗрд╡|'
    r'рдУрдо рдкреНрд░рдХрд╛рд╢ рдЪреМрдзрд░реА|рдУрдкреА рдЪреМрдзрд░реА|рдкрд╡рди рдкрдЯреЗрд▓|рднрд░рдд рд▓рд╛рд▓ рдкрдЯреЗрд▓)',
    re.IGNORECASE
)

# Pattern for "рд╢реНрд░реА X рдЬреА" (honorific patterns)
HONORIFIC_PATTERN = re.compile(
    r'(?:рдорд╛рдирдиреАрдп\s+)?(?:рд╢реНрд░реА|рд╢реНрд░реАрдорддреА|рдбреЙ\.?|рдкреНрд░реЛ\.?)\s+([\u0900-\u097F\s]+?)\s*рдЬреА',
    re.UNICODE
)

def _extract_people(self, text: str) -> List[str]:
    """
    Extract people names using patterns
    """
    people = set()
    
    # Strategy 1: Known names
    for match in PEOPLE_KEYWORDS.finditer(text):
        people.add(match.group(0))
    
    # Strategy 2: Honorific patterns
    for match in HONORIFIC_PATTERN.finditer(text):
        name = match.group(1).strip()
        if len(name.split()) <= 4:  # Reasonable name length
            people.add(name)
    
    return list(people)
```

**What happens:**
1. **Known Names**: Matches against politician database
2. **Pattern Detection**: Finds "рд╢реНрд░реА X рдЬреА" patterns
3. **Validation**: Filters out false positives (too long/short names)

---

#### **STEP 4: Event Type Classification**

This is where **AI/semantic understanding** helps:

```python
def _classify_event_type(self, text: str) -> Tuple[str, float]:
    """
    Classify the type of event/activity
    """
    text_lower = text.lower()
    
    # Rule-based classification with confidence scores
    event_patterns = {
        'birthday_wishes': (
            ['рдЬрдиреНрдорджрд┐рди', 'рдЬрдиреНрдорджрд┐рд╡рд╕', 'рд╢реБрднрдХрд╛рдордирд╛рдпреЗрдВ', 'рдмрдзрд╛рдИ'],
            0.95
        ),
        'meeting': (
            ['рдмреИрдардХ', 'рдореАрдЯрд┐рдВрдЧ', 'рдЪрд░реНрдЪрд╛', 'рд╡рд┐рдЪрд╛рд░-рд╡рд┐рдорд░реНрд╢'],
            0.90
        ),
        'rally': (
            ['рд░реИрд▓реА', 'рдЬрдирд╕рднрд╛', 'рд╕рднрд╛', 'рдорд╣рд╛рд╕рднрд╛'],
            0.90
        ),
        'inspection': (
            ['рдирд┐рд░реАрдХреНрд╖рдг', 'рджреМрд░рд╛', 'рд╕рдореАрдХреНрд╖рд╛'],
            0.85
        ),
        'inauguration': (
            ['рдЙрджреНрдШрд╛рдЯрди', 'рд▓реЛрдХрд╛рд░реНрдкрдг', 'рд╢рд┐рд▓рд╛рдиреНрдпрд╛рд╕', 'рднреВрдорд┐рдкреВрдЬрди'],
            0.90
        ),
        'scheme_announcement': (
            ['рдпреЛрдЬрдирд╛', 'рдШреЛрд╖рдгрд╛', 'рд╢реБрд░реБрдЖрдд', 'рд▓рд╛рдВрдЪ'],
            0.85
        ),
        'condolence': (
            ['рд╢реЛрдХ', 'рджреБрдЦ', 'рдирд┐рдзрди', 'рд╕реНрд╡рд░реНрдЧрд╡рд╛рд╕', 'рд╢реНрд░рджреНрдзрд╛рдВрдЬрд▓рд┐'],
            0.90
        ),
    }
    
    best_match = ('other', 0.30)  # Default
    
    for event_type, (keywords, base_confidence) in event_patterns.items():
        matches = sum(1 for keyword in keywords if keyword in text_lower)
        if matches > 0:
            # Confidence increases with multiple keyword matches
            confidence = min(base_confidence + (matches - 1) * 0.05, 0.99)
            if confidence > best_match[1]:
                best_match = (event_type, confidence)
    
    return best_match
```

**What happens:**
1. **Pattern Matching**: Looks for keywords associated with event types
2. **Confidence Scoring**: More matching keywords = higher confidence
3. **Best Match**: Returns highest-confidence classification

---

#### **STEP 5: Confidence Calculation**

```python
def _calculate_overall_confidence(
    self,
    event_confidence: float,
    has_locations: bool,
    has_people: bool,
    has_organizations: bool,
    has_schemes: bool
) -> float:
    """
    Calculate overall parsing confidence
    """
    # Base confidence from event classification
    confidence = event_confidence * 0.4
    
    # Add confidence for extracted entities
    if has_locations:
        confidence += 0.25
    if has_people:
        confidence += 0.20
    if has_organizations:
        confidence += 0.10
    if has_schemes:
        confidence += 0.05
    
    return round(confidence, 2)
```

**What happens:**
- **Event classification** contributes 40%
- **Locations** contribute 25%
- **People** contribute 20%
- **Organizations** contribute 10%
- **Schemes** contribute 5%

---

### **Complete Flow Diagram:**

```
тФМтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФР
тФВ  Raw Tweet Text тФВ
тФФтФАтФАтФАтФАтФАтФАтФАтФАтФмтФАтФАтФАтФАтФАтФАтФАтФАтФШ
         тФВ
         тЦ╝
тФМтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФР
тФВ  Preprocessing  тФВ тЖР Clean, normalize Unicode
тФФтФАтФАтФАтФАтФАтФАтФАтФАтФмтФАтФАтФАтФАтФАтФАтФАтФАтФШ
         тФВ
         тЦ╝
тФМтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФР
тФВ Entity ExtractionтФВ
тФЬтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФд
тФВ тАв Locations     тФВ тЖР Regex patterns + context
тФВ тАв People        тФВ тЖР Honorific patterns + DB
тФВ тАв Organizations тФВ тЖР Known org patterns
тФВ тАв Schemes       тФВ тЖР Scheme keywords
тФФтФАтФАтФАтФАтФАтФАтФАтФАтФмтФАтФАтФАтФАтФАтФАтФАтФАтФШ
         тФВ
         тЦ╝
тФМтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФР
тФВEvent ClassificationтФВ тЖР Keyword matching + scoring
тФФтФАтФАтФАтФАтФАтФАтФАтФАтФмтФАтФАтФАтФАтФАтФАтФАтФАтФШ
         тФВ
         тЦ╝
тФМтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФР
тФВConfidence Calc  тФВ тЖР Weighted entity presence
тФФтФАтФАтФАтФАтФАтФАтФАтФАтФмтФАтФАтФАтФАтФАтФАтФАтФАтФШ
         тФВ
         тЦ╝
тФМтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФР
тФВ Structured JSON тФВ
тФФтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФШ
```

---

## 3. LANGEXTRACT INTEGRATION POSSIBILITIES

### **What is LangExtract?**

LangExtract is a powerful tool for **multilingual entity extraction** that:
- Uses **linguistic patterns** to identify entities
- Provides **entity codes** (like ISO codes for languages)
- Builds **internal knowledge graphs** connecting similar entities
- Works across **multiple languages** (perfect for Hindi/English mix!)

### **Current Example (Your Understanding):**

```
Tweet: "рд░рд╛рдпрдЧрдврд╝ рдореЗрдВ рдмреИрдардХ"

LangExtract Output:
{
  "entities": [
    {
      "text": "рд░рд╛рдпрдЧрдврд╝",
      "type": "LOCATION",
      "code": "LOC_IN_CG_RAI",  тЖР Standardized code
      "confidence": 0.92,
      "aliases": ["Raigarh", "рд░рд╛рдпрдЧрдв", "RAIGARH"]
    },
    {
      "text": "рдмреИрдардХ",
      "type": "EVENT",
      "code": "EVENT_MEETING",
      "confidence": 0.88,
      "related_terms": ["рдореАрдЯрд┐рдВрдЧ", "meeting", "рдЪрд░реНрдЪрд╛"]
    }
  ]
}
```

---

### **How LangExtract Would Enhance Our System:**

#### **Benefit 1: Entity Normalization**

**Problem:** Different spellings of same entity
```
рд░рд╛рдпрдЧрдврд╝ = рд░рд╛рдпрдЧрдв = Raigarh = RAIGARH
```

**LangExtract Solution:**
```python
{
  "canonical_name": "рд░рд╛рдпрдЧрдврд╝",
  "code": "LOC_IN_CG_RAI",
  "variants": ["рд░рд╛рдпрдЧрдв", "Raigarh", "RAIGARH", "R├бyagaс╣Ыh"]
}
```

All variants map to **same code** тЖТ Better analytics!

---

#### **Benefit 2: Knowledge Graph Building**

**Problem:** Can't find relationships between entities

**LangExtract Solution:**
```
рд░рд╛рдпрдЧрдврд╝ (LOC_IN_CG_RAI)
  тФЬтФАтФА is_part_of тЖТ рдЫрддреНрддреАрд╕рдЧрдврд╝ (LOC_IN_CG)
  тФЬтФАтФА is_part_of тЖТ рднрд╛рд░рдд (LOC_IN)
  тФЬтФАтФА has_constituency тЖТ рд░рд╛рдпрдЧрдврд╝ рд╡рд┐рдзрд╛рдирд╕рднрд╛ (CONST_CG_RAI)
  тФФтФАтФА associated_people тЖТ рдУрдкреА рдЪреМрдзрд░реА (PERSON_OPCH)
```

This lets us answer questions like:
- "How many tweets mention Chhattisgarh constituencies?"
- "What events happen most in Raigarh district?"

---

#### **Benefit 3: Cross-Language Matching**

**Problem:** Mixed Hindi/English tweets

```
Tweet 1: "рд░рд╛рдпрдЧрдврд╝ рдореЗрдВ rally"
Tweet 2: "Raigarh рдореЗрдВ рдЬрдирд╕рднрд╛"
```

**LangExtract Solution:**
```
rally    тЖТ CODE: EVENT_RALLY
рдЬрдирд╕рднрд╛   тЖТ CODE: EVENT_RALLY

Both map to same code! тЬЕ
```

---

### **Proposed Integration Architecture:**

```
тФМтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФР
тФВ          TWEET INGESTION                        тФВ
тФФтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФмтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФШ
                 тФВ
                 тЦ╝
тФМтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФР
тФВ     CURRENT PARSER (Regex + AI)                 тФВ
тФВ  тАв Fast first-pass extraction                   тФВ
тФВ  тАв Identifies potential entities                тФВ
тФВ  тАв Assigns preliminary confidence               тФВ
тФФтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФмтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФШ
                 тФВ
                 тЦ╝
тФМтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФР
тФВ         HUMAN REVIEW QUEUE                      тФВ
тФВ  тАв Low confidence items (<70%)                  тФВ
тФВ  тАв Ambiguous entities                           тФВ
тФВ  тАв New entity types                             тФВ
тФФтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФмтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФШ
                 тФВ
                 тЦ╝ (User Approves)
тФМтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФР
тФВ         LANGEXTRACT PROCESSING                  тФВ
тФВ  тАв Entity normalization                         тФВ
тФВ  тАв Code assignment                              тФВ
тФВ  тАв Knowledge graph update                       тФВ
тФВ  тАв Cross-reference matching                     тФВ
тФФтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФмтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФШ
                 тФВ
                 тЦ╝
тФМтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФР
тФВ     CANONICAL ENTITY STORE                      тФВ
тФВ  {                                              тФВ
тФВ    "рд░рд╛рдпрдЧрдврд╝": {                                  тФВ
тФВ      "code": "LOC_IN_CG_RAI",                   тФВ
тФВ      "variants": [...],                         тФВ
тФВ      "relationships": [...],                    тФВ
тФВ      "tweet_count": 45,                         тФВ
тФВ      "first_seen": "2025-01-01",                тФВ
тФВ      "confidence": 0.95                         тФВ
тФВ    }                                            тФВ
тФВ  }                                              тФВ
тФФтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФмтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФШ
                 тФВ
                 тЦ╝
тФМтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФР
тФВ         ANALYTICS & INSIGHTS                    тФВ
тФВ  тАв Normalized entity counts                    тФВ
тФВ  тАв Relationship-based queries                  тФВ
тФВ  тАв Multi-language aggregation                  тФВ
тФФтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФШ
```

---

## 4. HUMAN-IN-THE-LOOP LEARNING SYSTEM

### **Current State:**
- Human reviews parsed tweets
- Can edit entities inline
- Corrections stored locally

### **Proposed Enhancement:**

#### **Phase 1: Correction Storage**
```typescript
// When human corrects a tweet
{
  "tweet_id": "1978808458720797118",
  "corrections": {
    "event_type": {
      "before": "rally",
      "after": "birthday_wishes",
      "confidence_before": 0.45,
      "confidence_after": 1.0
    },
    "locations": {
      "added": ["рдЕрдВрддрд╛рдЧрдврд╝"],
      "removed": [],
      "reason": "Missed constituency name"
    }
  },
  "reviewed_by": "human",
  "reviewed_at": "2025-10-17T14:30:00Z"
}
```

#### **Phase 2: Pattern Learning**

When human makes corrections, system learns:

```python
# Example: Human repeatedly corrects "рд░реИрд▓реА" тЖТ birthday_wishes

# System learns new pattern:
NEW_PATTERN = {
  "trigger": "рдЬрдиреНрдорджрд┐рди",
  "event_type": "birthday_wishes",
  "confidence": 0.95,
  "learned_from": ["tweet_123", "tweet_456"],
  "approval_count": 5
}

# Add to event classification rules
self.learned_patterns.append(NEW_PATTERN)
```

#### **Phase 3: Feedback Loop**

```
тФМтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФР
тФВ New Tweet    тФВ
тФФтФАтФАтФАтФАтФАтФАтФмтФАтФАтФАтФАтФАтФАтФАтФШ
       тФВ
       тЦ╝
тФМтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФР
тФВ Parse with   тФВ
тФВ Current RulesтФВ
тФФтФАтФАтФАтФАтФАтФАтФмтФАтФАтФАтФАтФАтФАтФАтФШ
       тФВ
       тЦ╝
тФМтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФР     YES      тФМтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФР
тФВ Confidence   тФЬтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФА>тФВ Auto-approve тФВ
тФВ >= 80%?      тФВ               тФФтФАтФАтФАтФАтФАтФАтФмтФАтФАтФАтФАтФАтФАтФАтФШ
тФФтФАтФАтФАтФАтФАтФАтФмтФАтФАтФАтФАтФАтФАтФАтФШ                      тФВ
       тФВ NO                            тФВ
       тЦ╝                               тФВ
тФМтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФР                      тФВ
тФВ Human Review тФВ                      тФВ
тФФтФАтФАтФАтФАтФАтФАтФмтФАтФАтФАтФАтФАтФАтФАтФШ                      тФВ
       тФВ                               тФВ
       тЦ╝                               тФВ
тФМтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФР                      тФВ
тФВ Corrections? тФВ                      тФВ
тФФтФАтФАтФАтФАтФАтФАтФмтФАтФАтФАтФАтФАтФАтФАтФШ                      тФВ
       тФВ YES                           тФВ
       тЦ╝                               тФВ
тФМтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФР                      тФВ
тФВ Learn PatternтФВ                      тФВ
тФВ Update Rules тФВ                      тФВ
тФФтФАтФАтФАтФАтФАтФАтФмтФАтФАтФАтФАтФАтФАтФАтФШ                      тФВ
       тФВ                               тФВ
       тЦ╝                               тЦ╝
тФМтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФР
тФВ     Store in Database              тФВ
тФВ   (with learned patterns)          тФВ
тФФтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФШ
```

#### **Phase 4: Pattern Confidence**

```python
class PatternLearner:
    def __init__(self):
        self.patterns = {}
    
    def learn_from_correction(self, correction):
        """
        Learn new patterns from human corrections
        """
        # Extract pattern
        trigger = correction['trigger_words']
        result = correction['correct_classification']
        
        # Create pattern signature
        pattern_id = f"{trigger}_{result}"
        
        if pattern_id not in self.patterns:
            self.patterns[pattern_id] = {
                'trigger': trigger,
                'result': result,
                'confidence': 0.6,  # Start low
                'approval_count': 1,
                'rejection_count': 0,
                'examples': [correction['tweet_id']]
            }
        else:
            # Increase confidence with more approvals
            pattern = self.patterns[pattern_id]
            pattern['approval_count'] += 1
            pattern['examples'].append(correction['tweet_id'])
            
            # Confidence formula
            total = pattern['approval_count'] + pattern['rejection_count']
            pattern['confidence'] = pattern['approval_count'] / total
    
    def get_active_patterns(self, min_confidence=0.8, min_examples=3):
        """
        Get patterns ready for production use
        """
        return [
            p for p in self.patterns.values()
            if p['confidence'] >= min_confidence 
            and len(p['examples']) >= min_examples
        ]
```

---

## 5. IMPLEMENTATION ROADMAP

### **Phase 1: Enhanced Human Review UI** (Now!)
- тЬЕ Editable fields for all entities
- тЬЕ Add/remove entities dynamically
- тЬЕ Confidence override
- тЬЕ Correction reasoning field
- тЬЕ Keyboard shortcuts (A=Approve, E=Edit, R=Reject)

### **Phase 2: Correction Storage** (Next)
- Store corrections in `parsed_events` table
- Add `corrections_log` column (JSONB)
- Track correction history
- API endpoint for submitting corrections

### **Phase 3: Pattern Learning** (Week 2)
- Build `PatternLearner` class
- Extract patterns from corrections
- Test patterns against validation set
- Promote high-confidence patterns to production

### **Phase 4: LangExtract Integration** (Week 3-4)
- Set up LangExtract service
- Build entity code mapping
- Create knowledge graph database
- Implement cross-language matching

### **Phase 5: Advanced Analytics** (Week 5+)
- Relationship-based queries
- Multi-language aggregation
- Predictive event classification
- Automated tagging suggestions

---

## ЁЯУК **EXPECTED IMPROVEMENTS:**

| Metric | Current | After Phase 3 | After Phase 4 |
|--------|---------|---------------|---------------|
| Location Detection | 77% | 85% | 95% |
| People Extraction | 66% | 78% | 90% |
| Event Classification | 85% | 90% | 95% |
| Cross-language Matching | N/A | N/A | 95% |
| Entity Normalization | 60% | 70% | 98% |

---

## ЁЯОп **KEY TAKEAWAYS:**

1. **Current System**: Hybrid regex + AI approach
2. **Strengths**: Fast, reasonable accuracy, language-specific
3. **Weaknesses**: No normalization, no cross-language, limited learning
4. **LangExtract Benefit**: Entity codes, knowledge graphs, multi-language
5. **Human Learning**: Corrections тЖТ Patterns тЖТ Better parsing
6. **Final Vision**: Self-improving, multi-language, world-class parser

---

**This document will be updated as we implement each phase.**

